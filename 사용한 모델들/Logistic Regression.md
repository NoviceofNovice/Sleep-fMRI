## Logistic Regression

간단한 모델부터 적용해보기 위해 로지스틱 회귀를 사용해보았다.

### 동작원리

로지스틱 회귀의 동작원리는 다음과 같다.

* 선형결합
* Logit을 확률로 변환
* 분류 결정

선형결합은 아래의 수식을 참고하면 된다.

$$
z = b + x_1w_1 + x_2w_2 + x_3w_3 + .... + x_nw_n
$$


여기서 z는 선형결합 값이 된다.

선형결합값이 구해지면 해당 값을 sigmoid 함수에 통과시켜서 0~1사이의 확률값을 얻는다.

$$
p = \frac{1}{1 + e^{-z}}
$$

p갑은 0과 1사이의 값이 나오는데, 위 p를 기준으로 양성, 음성을 나눈다. 대충 생각해서 만일 P가 0.5이상이면 양성, 그 미만이면 음성이라는 판정을 내릴 수도 있을 것이다.

### 모델 학습

모델의 목적은 예측 값과 실제 값의 차이를 최소화 하는 것이다. 그러려면 모델은 어떤 값을 조정해야 할까?

당연히, p를 잘 만들어야 하는데, p는 선형결합을 변형한 것이기 때문에 선형결합(z)을 잘 조정해야 한다.

그러기 위해서는 가중치를 잘 조정해줘야 하는데, 위 모델은 반복된 학습을 통해서 최적화된 가중치를 찾는 것이 목적이다.

위 과정을 위해서 손실함수를 사용한다.

$$
L(Y,p) = -Ylog(p) - (1-Y)log(1-p)
$$
